{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Counterfactual Sample Generation for Microaggression Detection\n",
        "\n",
        "Generate counterfactual (non-microaggressive) samples from microaggressive texts using few-shot\n",
        "prompting with GPT to create a balanced binary classification dataset.\n",
        "\n",
        "## Pipeline:\n",
        "1. **Setup**: Load dataset and configure API\n",
        "2. **Generate & Balance**: For each split, generate counterfactuals and combine with originals\n",
        "3. **Save**: Output balanced train/validation/test CSV files"
      ],
      "metadata": {
        "id": "mO03k4t9uOt7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prtgO-BWt94A"
      },
      "source": [
        "## 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89xWctGGt94A"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "# Configuration\n",
        "BASE_PATH = '/content/drive/MyDrive/266_project/'\n",
        "DATASET_PATH = BASE_PATH + 'selfMA_ds'\n",
        "RANDOM_SEED = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxT6sihqt94B",
        "outputId": "9ca6c395-8a10-466c-95e5-4dab05f5a3b5"
      },
      "source": [
        "# Mount Google Drive and load dataset\n",
        "drive.mount('/content/drive')\n",
        "selfMA = DatasetDict.load_from_disk(DATASET_PATH)\n",
        "\n",
        "print(\"Dataset loaded:\")\n",
        "print(selfMA)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset loaded:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1040\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 130\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 130\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mFrFVlWt94C",
        "outputId": "9c49fbf9-f767-4b8f-8be9-46074f1984c0"
      },
      "source": [
        "# Setup OpenAI API\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "print(\"OpenAI API key configured.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB9YrjHwt94D"
      },
      "source": [
        "## 2. Counterfactual Generation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sersm8sVt94D"
      },
      "source": [
        "Define a function that uses few-shot prompting to transform microaggressive text into non-microaggressive equivalents while preserving the core neutral sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSJMLpJCt94D"
      },
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "def generate_non_microaggressive_equivalent(microaggressive_text):\n",
        "    \"\"\"\n",
        "    Transform microaggressive text into a non-microaggressive equivalent.\n",
        "    Uses few-shot prompting with examples to guide the transformation.\n",
        "\n",
        "    Args:\n",
        "        microaggressive_text: The input text containing microaggression\n",
        "\n",
        "    Returns:\n",
        "        Non-microaggressive equivalent text\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"Task: Transform the given microaggressive text into a non-microaggressive equivalent.\n",
        "The non-microaggressive equivalent should remove any bias, insensitivity, or invalidation present\n",
        "in the original text, while retaining the core positive or neutral sentiment if applicable.\n",
        "Do not repeat the original text in the answer. Do not use labels in the answer.\n",
        "Produce the non-microaggressive equivalent phrase as the answer.\n",
        "\n",
        "Examples:\n",
        "Microaggressive: \"You're very articulate for someone like you.\"\n",
        "Non-Microaggressive: \"Your presentation was very articulate.\"\n",
        "\n",
        "Microaggressive: \"Where are you really from?\"\n",
        "Non-Microaggressive: \"Where did you grow up?\"\n",
        "\n",
        "Microaggressive: \"You must be good at math since you're Asian.\"\n",
        "Non-Microaggressive: \"You are really good at math.\"\n",
        "\n",
        "Microaggressive: \"You're too pretty to be a software engineer.\"\n",
        "Non-Microaggressive: \"You are pretty.\"\n",
        "\n",
        "Microaggressive: \"Are you sure you want to lead this project?\"\n",
        "Non-Microaggressive: \"Can you lead this project?\"\n",
        "\n",
        "Microaggressive: \"You're surprisingly smart for someone like you.\"\n",
        "Non-Microaggressive: \"You are really smart.\"\n",
        "\n",
        "Microaggressive: \"I didn't expect someone like you to be this good at coding.\"\n",
        "Non-Microaggressive: \"You are good at coding.\"\n",
        "\n",
        "Microaggressive: \"Are you the diversity hire?\"\n",
        "Non-Microaggressive: \"Are you the new hire?\"\n",
        "\n",
        "Microaggressive: \"You look too feminine to be a scientist.\"\n",
        "Non-Microaggressive: \"You are a scientist.\"\n",
        "\n",
        "Microaggressive: \"You're lucky you're cute.\"\n",
        "Non-Microaggressive: \"You're cute.\"\n",
        "\n",
        "Microaggressive: \"{microaggressive_text}\"\n",
        "Non-Microaggressive:\n",
        "\"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4.1\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return resp.choices[0].message.content.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mFRGLsRt94E"
      },
      "source": [
        "## 3. Generate Counterfactual Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdQ1jcUDt94F"
      },
      "source": [
        "For each split (train/validation/test):\n",
        "- Generate counterfactual for each microaggressive text (label 0)\n",
        "- Keep original microaggressive texts (label 1)  \n",
        "- Combine and shuffle within the split\n",
        "- Save to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQoc8RK3t94F"
      },
      "source": [
        "def process_split(split_name, dataset_split):\n",
        "    \"\"\"\n",
        "    Process a single split: generate counterfactuals, combine with originals, shuffle.\n",
        "\n",
        "    Returns a balanced DataFrame with 'text' and 'label' columns.\n",
        "    \"\"\"\n",
        "    texts = dataset_split['text']\n",
        "    labels = dataset_split['label']\n",
        "\n",
        "    original_samples = []      # Label 1: microaggressive\n",
        "    counterfactual_samples = [] # Label 0: non-microaggressive\n",
        "\n",
        "    print(f\"Processing {split_name} split ({len(texts)} samples)...\")\n",
        "\n",
        "    for i, (text, label) in enumerate(zip(texts, labels)):\n",
        "        if label in [1, 2]:  # Microaggressive text\n",
        "            # Keep original as label 1\n",
        "            original_samples.append({'text': text, 'label': 1})\n",
        "\n",
        "            # Generate counterfactual as label 0\n",
        "            try:\n",
        "                counterfactual = generate_non_microaggressive_equivalent(text)\n",
        "                counterfactual_samples.append({'text': counterfactual, 'label': 0})\n",
        "            except Exception as e:\n",
        "                print(f\"  Error at sample {i}: {e}\")\n",
        "                counterfactual_samples.append({'text': f\"Error: {e}\", 'label': 0})\n",
        "\n",
        "            if (i + 1) % 50 == 0:\n",
        "                print(f\"  Processed {i + 1}/{len(texts)}...\")\n",
        "\n",
        "    # Combine and shuffle\n",
        "    df = pd.concat([\n",
        "        pd.DataFrame(original_samples),\n",
        "        pd.DataFrame(counterfactual_samples)\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "    print(f\"  Completed: {len(df)} samples (balanced: {len(original_samples)} + {len(counterfactual_samples)})\")\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvR1moVNt94F",
        "outputId": "a3a89abf-a674-42b0-a618-cbb66eca1719"
      },
      "source": [
        "# Process all splits and save\n",
        "results = {}\n",
        "\n",
        "for split_name in ['train', 'validation', 'test']:\n",
        "    df = process_split(split_name, selfMA[split_name])\n",
        "    results[split_name] = df\n",
        "\n",
        "    # Save to CSV\n",
        "    output_path = f\"{BASE_PATH}balanced_{split_name}.csv\"\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"  Saved to {output_path}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing train split (1040 samples)...\n",
            "  Processed 50/1040...\n",
            "  Processed 100/1040...\n",
            "  Processed 150/1040...\n",
            "  Processed 200/1040...\n",
            "  Processed 250/1040...\n",
            "  Processed 300/1040...\n",
            "  Processed 350/1040...\n",
            "  Processed 400/1040...\n",
            "  Processed 450/1040...\n",
            "  Processed 500/1040...\n",
            "  Processed 550/1040...\n",
            "  Processed 600/1040...\n",
            "  Processed 650/1040...\n",
            "  Processed 700/1040...\n",
            "  Processed 750/1040...\n",
            "  Processed 800/1040...\n",
            "  Processed 850/1040...\n",
            "  Processed 900/1040...\n",
            "  Processed 950/1040...\n",
            "  Processed 1000/1040...\n",
            "  Completed: 2080 samples (balanced: 1040 + 1040)\n",
            "  Saved to /content/drive/MyDrive/266_project/balanced_train.csv\n",
            "\n",
            "Processing validation split (130 samples)...\n",
            "  Processed 50/130...\n",
            "  Processed 100/130...\n",
            "  Completed: 260 samples (balanced: 130 + 130)\n",
            "  Saved to /content/drive/MyDrive/266_project/balanced_validation.csv\n",
            "\n",
            "Processing test split (130 samples)...\n",
            "  Processed 50/130...\n",
            "  Processed 100/130...\n",
            "  Completed: 260 samples (balanced: 130 + 130)\n",
            "  Saved to /content/drive/MyDrive/266_project/balanced_test.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X4kxt74t94F"
      },
      "source": [
        "## 4. Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2ltnRzPt94F"
      },
      "source": [
        "Load the generated counterfactual samples and combine them with original\n",
        "microaggressive texts to create a balanced binary classification dataset:\n",
        "- **Label 0**: Non-microaggressive (generated counterfactuals)\n",
        "- **Label 1**: Microaggressive (original texts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRXaeJbBt94G",
        "outputId": "4b81a921-f6a2-4a10-e80b-f7eb948cc788"
      },
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"DATASET GENERATION COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "total_samples = sum(len(df) for df in results.values())\n",
        "\n",
        "print(f\"\"\"\n",
        "Results:\n",
        "--------\n",
        "Train:      {len(results['train']):,} samples ({len(results['train'])//2} per class)\n",
        "Validation: {len(results['validation']):,} samples ({len(results['validation'])//2} per class)\n",
        "Test:       {len(results['test']):,} samples ({len(results['test'])//2} per class)\n",
        "\n",
        "Total:      {total_samples:,} samples\n",
        "\n",
        "Class Balance: 1:1 (perfectly balanced in each split)\n",
        "\n",
        "Output Files:\n",
        "- {BASE_PATH}balanced_train.csv\n",
        "- {BASE_PATH}balanced_validation.csv\n",
        "- {BASE_PATH}balanced_test.csv\n",
        "\"\"\")\n",
        "\n",
        "# Show sample from each split\n",
        "for split_name, df in results.items():\n",
        "    print(f\"\\n{split_name.upper()} sample:\")\n",
        "    print(df.head(4).to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATASET GENERATION COMPLETE\n",
            "============================================================\n",
            "\n",
            "Results:\n",
            "--------\n",
            "Train:      2,080 samples (1040 per class)\n",
            "Validation: 260 samples (130 per class)\n",
            "Test:       260 samples (130 per class)\n",
            "\n",
            "Total:      2,600 samples\n",
            "\n",
            "Class Balance: 1:1 (perfectly balanced in each split)\n",
            "\n",
            "Output Files:\n",
            "- /content/drive/MyDrive/266_project/balanced_train.csv\n",
            "- /content/drive/MyDrive/266_project/balanced_validation.csv\n",
            "- /content/drive/MyDrive/266_project/balanced_test.csv\n",
            "\n",
            "\n",
            "TRAIN sample:\n",
            "                                                                                         text  label\n",
            "                                                         I'm glad to have you as my roommate.      0\n",
            "                                                                    THERE'S NO BITCH IN TEAM.      1\n",
            "                                                                              Are you normal?      1\n",
            "Hi Miss [woman with a PhD], do you know where Dr. [male colleague without a PhD]'s office is?      1\n",
            "\n",
            "VALIDATION sample:\n",
            "                                                      text  label\n",
            "                    Why isn't there a white history month?      1\n",
            "                                     You are good at math.      0\n",
            "      Would you like to join us in our New Year's contest?      0\n",
            "Would you be interested in participating in our interview?      0\n",
            "\n",
            "TEST sample:\n",
            "                                                                                                                                                          text  label\n",
            "When I first saw you in class, I thought 'Whoa! She's really hot.' Then you answered a question, and I thought 'Man! Big tits, blonde hair, and smart? No way!      1\n",
            "                                                                                                                    Iâ€™ll make sure to use respectful language.      0\n",
            "                                                                                                                                                    Great job!      0\n",
            "                                                                                                     I raised my girls in a way that I felt was best for them.      0\n"
          ]
        }
      ]
    }
  ]
}