{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Z8LeEMJRTz"
   },
   "source": [
    "### Bert Base Cased ###\n",
    "\n",
    "Train and test on ISHate dataset, then evlauate with the microaggressions dataset. Following example from previous assigments & notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqB3DQfxJUKI"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q torchinfo\n",
    "!pip install -U -q datasets\n",
    "!pip install -q evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jjqPdqM-WI3",
    "outputId": "b3e2381a-86a6-47e8-fc45-acfba96c325c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAwK53ldJVm3"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "import evaluate\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "splits = {\n",
    "    'train': 'ishate_train.parquet.gzip',\n",
    "    'validation': 'ishate_dev.parquet.gzip',\n",
    "    'test': 'ishate_test.parquet.gzip'\n",
    "}\n",
    "\n",
    "df_train = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"train\"])\n",
    "df_val = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"validation\"])\n",
    "df_test = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"test\"])\n",
    "max_sequence_length = 128\n",
    "\n",
    "# create DatasetDict\n",
    "ishate_dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"validation\": Dataset.from_pandas(df_val),\n",
    "    \"test\": Dataset.from_pandas(df_test)\n",
    "})\n",
    "\n",
    "# Encode labels, similar to how we did above for the CNN.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(ishate_dataset['train']['hateful_layer'])\n",
    "y_val_encoded = label_encoder.transform(ishate_dataset['validation']['hateful_layer'])\n",
    "y_test_encoded = label_encoder.transform(ishate_dataset['test']['hateful_layer'])\n",
    "ishate_train_data = ishate_dataset['train'].add_column('label', y_train_encoded.tolist())\n",
    "ishate_val_data = ishate_dataset['validation'].add_column('label', y_val_encoded.tolist())\n",
    "ishate_test_data = ishate_dataset['test'].add_column('label', y_test_encoded.tolist())\n",
    "\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "    # Ensure text is a list of strings\n",
    "    text = data['cleaned_text']\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "            text,\n",
    "            max_length=max_sequence_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True\n",
    "            # return_tensors=\"pt\"\n",
    "    )\n",
    "    return encoded\n",
    "\n",
    "\n",
    "metric = evaluate.load('accuracy')\n",
    "f1  = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        **metric.compute(predictions=predictions, references=labels),\n",
    "        \"f1_macro:\": f1.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5HqLZ16JX1F"
   },
   "outputs": [],
   "source": [
    "def fine_tune_classification_model(classification_model,\n",
    "                                   tokenizer,\n",
    "                                   train_data,\n",
    "                                   dev_data,\n",
    "                                   batch_size = 16,\n",
    "                                   num_epochs = 2,\n",
    "                                   learning_rate=2e-5):\n",
    "    \"\"\"\n",
    "    Preprocess the data using the given tokenizer (we've give you the code for that part).\n",
    "    Create the training arguments and trainer for the given model and data (write your code for that).\n",
    "    Then train it.\n",
    "    \"\"\"\n",
    "\n",
    "    preprocessed_train_data = train_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "    preprocessed_dev_data = dev_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "\n",
    "    # Referencing lesson 4 notebook & assignment 2 as an example:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=\"bert_ishate\",\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      per_device_eval_batch_size=batch_size,\n",
    "      num_train_epochs=num_epochs,\n",
    "      learning_rate=learning_rate,\n",
    "      eval_strategy=\"epoch\",\n",
    "      save_strategy=\"epoch\",\n",
    "      report_to='none',\n",
    "      load_best_model_at_end = True,\n",
    "      metric_for_best_model = \"f1_macro\",\n",
    "      seed = 42\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=classification_model,\n",
    "      args=training_args,\n",
    "      train_dataset=preprocessed_train_data,\n",
    "      eval_dataset=preprocessed_dev_data,\n",
    "      compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bZ_FlMuJauu",
    "outputId": "9b8b5b0c-4191-4c45-a384-e32975030de6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_name = \"bert-base-cased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_name)\n",
    "bert_classification_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_name, num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "ed66ffa1dda7435fa10d696ec0c85b97",
      "afd9585ef21b4d779115477d1552f563"
     ]
    },
    "id": "rjxlbTLCJct0",
    "outputId": "a94baafb-568c-4daa-da3a-447520c7fa59"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed66ffa1dda7435fa10d696ec0c85b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/55023 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd9585ef21b4d779115477d1552f563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6878' max='6878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6878/6878 40:30, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.393125</td>\n",
       "      <td>0.856652</td>\n",
       "      <td>0.845382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.491586</td>\n",
       "      <td>0.863980</td>\n",
       "      <td>0.856049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_base_cased_trainer = fine_tune_classification_model(bert_classification_model, bert_tokenizer, ishate_train_data, ishate_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281,
     "referenced_widgets": [
      "5cb4838adbf94daca86d1d213cd72517",
      "40ef9e4af0b4461b83996ab10581afaf",
      "98cebab6c3d84d3987218f40b5810188",
      "09e926929b364aca8534763d768e3d67",
      "050ed20027cd49a984be320606f51aea",
      "ddb998c27c754be59926da3b56604852",
      "7f9cf82a416b45aa8b80068500d46af3",
      "75b78130d20045218fafaaf2f9035fa7",
      "1e5b5c8d94434a0ab70b1bae38682137",
      "aebd587d16314a6881b6578530e582aa",
      "a010a1c05faa43e7a4db03f4e848143d"
     ]
    },
    "id": "Ky1oiQ4cJeZs",
    "outputId": "74895806-8efb-4467-bf08-188aa2035843"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb4838adbf94daca86d1d213cd72517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8764\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HS       0.83      0.86      0.84      1687\n",
      "      Non-HS       0.91      0.89      0.90      2681\n",
      "\n",
      "    accuracy                           0.88      4368\n",
      "   macro avg       0.87      0.87      0.87      4368\n",
      "weighted avg       0.88      0.88      0.88      4368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_test_data = ishate_test_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': bert_tokenizer})\n",
    "predictions = bert_base_cased_trainer.predict(preprocessed_test_data)\n",
    "preprocessed_test_pred = np.argmax(predictions.predictions, axis=1)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "test_accuracy = accuracy_score(y_test_encoded, preprocessed_test_pred)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, preprocessed_test_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsLiietNE1jo"
   },
   "source": [
    "### Now train on iSarcasm Eval: ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "1871a17fa8f549139c2f859aadb4f35d",
      "48ac716e35f142ab9903cc777ad4e561",
      "22f6afb32f9f421593ef66a96c7c2b6a",
      "a9f92eac247741bda3fc4161864c8999",
      "729fc699e35141d1bf21b10d143b5537",
      "fa0b0caa60824ce796ae0900fd8cfee4",
      "f83953f4bf3b4913b0d1f41c87866480",
      "bd4d5ca4391a46f38acdd72b341ac1b6",
      "e7652697e2fb47f383dbea101c941c61",
      "3de1cdb3547f45668999d12f66df7085",
      "ea70a01b934545a1810f0b464118e35b",
      "288c2e30ac264ac9a1315829926e7162",
      "8608908b633748eab47b8006574a3d7b",
      "0bdb44870eb94f3696743b1d4c07ba1e",
      "c8848e0c64a74e1797e767675884415d",
      "5697f7641c534d3b98112b85543b597a",
      "ff48d6d23f914673abb8fba17d035771",
      "70c6c4baf9504a8f86de7c2bdd2490bb",
      "7b8e0600ea9c43eba657a92533cd83e6",
      "b6010196538445e7b11f8b054c4d98c3",
      "28331bbdeb6f4244bcf22248758ddf75",
      "f90aec3396df4972a8b05371a1196ff5"
     ]
    },
    "id": "7HWxDa6hE6sJ",
    "outputId": "fe1a7ee6-902a-4720-d8bc-7695fb25b034"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1871a17fa8f549139c2f859aadb4f35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2774 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288c2e30ac264ac9a1315829926e7162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [348/348 02:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.565151</td>\n",
       "      <td>0.750720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.566316</td>\n",
       "      <td>0.749280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isarc_train_df = pd.read_csv('/content/drive/MyDrive/W266_Fall2025_Neeha_Kotte/final_project/train_EN_iSarcasmEval.csv')\n",
    "isarc_test_df = pd.read_csv('/content/drive/MyDrive/W266_Fall2025_Neeha_Kotte/final_project/task_A_En_test.csv')\n",
    "isarc_test_df.head()\n",
    "\n",
    "isarc_train_cleaned_df = isarc_train_df.copy()\n",
    "isarc_train_cleaned_df['cleaned_text'] = isarc_train_df['tweet']\n",
    "isarc_train_cleaned_df['label'] = isarc_train_df['sarcastic']\n",
    "\n",
    "isarc_test_cleaned_df = isarc_test_df.copy()\n",
    "isarc_test_cleaned_df['cleaned_text'] = isarc_test_df['text']\n",
    "isarc_test_cleaned_df['label'] = isarc_test_df['sarcastic']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "isarc_train_split, isarc_val_split = train_test_split(\n",
    "    isarc_train_cleaned_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=isarc_train_cleaned_df['label'] if 'label' in isarc_train_cleaned_df.columns else None\n",
    ")\n",
    "\n",
    "isarc_train_split['cleaned_text'] = isarc_train_split['cleaned_text'].fillna('').astype(str)\n",
    "isarc_val_split['cleaned_text'] = isarc_val_split['cleaned_text'].fillna('').astype(str)\n",
    "isarc_test_cleaned_df['cleaned_text'] = isarc_test_cleaned_df['cleaned_text'].fillna('').astype(str)\n",
    "\n",
    "\n",
    "isarc_train_dataset = Dataset.from_pandas(isarc_train_split[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "isarc_val_dataset = Dataset.from_pandas(isarc_val_split[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "isarc_test_dataset = Dataset.from_pandas(isarc_test_cleaned_df[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "\n",
    "sarcasm_trainer = fine_tune_classification_model(\n",
    "    bert_base_cased_trainer.model,\n",
    "    bert_tokenizer,\n",
    "    isarc_train_dataset,\n",
    "    isarc_val_dataset,\n",
    "    batch_size=16,\n",
    "    num_epochs=2,\n",
    "   learning_rate=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "cR0hdG9B7zpY",
    "outputId": "dc788f14-eb27-4a2b-cf78-0bc7759be4dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ISHate Test Performance:\n",
      "  Before sarcasm training: 0.8764\n",
      "  After sarcasm training:  0.4412\n",
      "  Change:                  -0.4352\n"
     ]
    }
   ],
   "source": [
    "# Check that the model can still detect hate speech, even after training on sarcasm\n",
    "predictions_after_sarc = sarcasm_trainer.predict(preprocessed_test_data)\n",
    "y_test_pred_after = np.argmax(predictions_after_sarc.predictions, axis=1)\n",
    "test_accuracy_after = accuracy_score(y_test_encoded, y_test_pred_after)\n",
    "\n",
    "print(f\"\\nISHate Test Performance:\")\n",
    "print(f\"  Before sarcasm training: {test_accuracy:.4f}\")\n",
    "print(f\"  After sarcasm training:  {test_accuracy_after:.4f}\")\n",
    "print(f\"  Change:                  {(test_accuracy_after - test_accuracy):+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWI-qFXhJfrA"
   },
   "source": [
    "### Microaggressions Evaluation:\n",
    "Followed same initial load and format steps as Carlos, but tokenizer here is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "AEuQTH-MLE2E",
    "outputId": "caee6075-3ee8-486d-8c67-c164a2e7e811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying encoding: utf-8\n",
      "❌ Failed with utf-8: 'utf-8' codec can't decode byte 0xe2 in position 17: invalid continuation byte...\n",
      "Trying encoding: latin-1\n",
      "✅ Successfully loaded with latin-1 encoding\n",
      "Dataset shape: (171, 2)\n",
      "Columns: ['speech', 'label']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"y_micro_encoded = label_encoder\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"speech\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"That's a strange name, is it foreign?\",\n          \"Where are you really from?\",\n          \"Are you sure you want to lead this project?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-80ec686f-da9a-4712-8532-177699796757\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You're very articulate for someone like you.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where are you really from?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You're not like other girls.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You must be good at math since you're Asian.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're too pretty to be a software engineer.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Are you sure you want to lead this project?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You don't look gay.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>You are a credit to your race.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>That's a strange name, is it foreign?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Do you even understand this topic?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80ec686f-da9a-4712-8532-177699796757')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-80ec686f-da9a-4712-8532-177699796757 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-80ec686f-da9a-4712-8532-177699796757');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-347124d9-51e7-4a52-93cd-e04a151c9711\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-347124d9-51e7-4a52-93cd-e04a151c9711')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-347124d9-51e7-4a52-93cd-e04a151c9711 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                         speech  label\n",
       "0  You're very articulate for someone like you.      1\n",
       "1                    Where are you really from?      1\n",
       "2                  You're not like other girls.      1\n",
       "3  You must be good at math since you're Asian.      1\n",
       "4  You're too pretty to be a software engineer.      1\n",
       "5   Are you sure you want to lead this project?      1\n",
       "6                           You don't look gay.      1\n",
       "7                You are a credit to your race.      1\n",
       "8         That's a strange name, is it foreign?      1\n",
       "9            Do you even understand this topic?      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "speech    object\n",
      "label      int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "speech    0\n",
      "label     0\n",
      "dtype: int64\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0    87\n",
      "1    84\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample texts:\n",
      "1. Label 1: You're very articulate for someone like you.\n",
      "2. Label 1: Where are you really from?\n",
      "3. Label 1: You're not like other girls.\n"
     ]
    }
   ],
   "source": [
    "micro_agg_url = \"https://huggingface.co/spaces/khanak27/microaggressionsdetector/resolve/main/micro_agg.csv\"\n",
    "# Try different encodings to handle Unicode issues\n",
    "encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1', 'utf-8-sig']\n",
    "\n",
    "df_micro = None\n",
    "for encoding in encodings_to_try:\n",
    "    try:\n",
    "        print(f\"Trying encoding: {encoding}\")\n",
    "        df_micro = pd.read_csv(micro_agg_url, encoding=encoding)\n",
    "        print(f\"✅ Successfully loaded with {encoding} encoding\")\n",
    "        break\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"❌ Failed with {encoding}: {str(e)[:100]}...\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Other error with {encoding}: {str(e)[:100]}...\")\n",
    "        continue\n",
    "\n",
    "if df_micro is None:\n",
    "    print(\"❌ Failed to load dataset with any encoding. Trying with error handling...\")\n",
    "    try:\n",
    "        df_micro = pd.read_csv(micro_agg_url, encoding='utf-8', encoding_errors='replace')\n",
    "        print(\"✅ Loaded with UTF-8 and error replacement\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Final attempt failed: {e}\")\n",
    "        raise\n",
    "\n",
    "print(f\"Dataset shape: {df_micro.shape}\")\n",
    "print(f\"Columns: {df_micro.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(df_micro.head(10))\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df_micro.dtypes)\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_micro.isnull().sum())\n",
    "\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_micro['label'].value_counts().sort_index())\n",
    "\n",
    "# Check for any text preprocessing needed\n",
    "print(f\"\\nSample texts:\")\n",
    "for i in range(3):\n",
    "    print(f\"{i+1}. Label {df_micro.iloc[i]['label']}: {df_micro.iloc[i]['speech']}\")\n",
    "\n",
    "\n",
    "\n",
    "df_micro['cleaned_text'] = df_micro['speech']\n",
    "def map_micro_labels_to_hate_speech(micro_label):\n",
    "    \"\"\"Map microaggression labels to hate speech labels\"\"\"\n",
    "    if micro_label == 1:  # Microaggression\n",
    "        return 'HS'  # Map to hateful speech\n",
    "    else:  # Normal speech\n",
    "        return 'Non-HS'  # Map to non-hateful speech\n",
    "\n",
    "# Apply the mapping\n",
    "df_micro['mapped_label'] = df_micro['label'].apply(map_micro_labels_to_hate_speech)\n",
    "y_micro_encoded = label_encoder.transform(df_micro['mapped_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "470feafa7bc1429e80f82f4211c2cdb0",
      "c7356db0e8ea4ac6b8ddd43ebb7015b9",
      "ad45b13ca4dc4fbfb96bfa837ca0dd83",
      "84dfff7909bf413a865f2219d64d0da0",
      "8824db8aad6b4175b8ac728befdd9728",
      "4b750f3d441b45928e12e3a439301833",
      "4a4a8e33eebf4865b512d63ab96e3713",
      "8a145a483c5a4dccbe0a8e8c50114d46",
      "59bd168a3cad40d0b7018334432b9ecc",
      "48f05a75773e45df936069464fad4f3d",
      "a4ab4c1c6d4645258c1ee425c6d9442a"
     ]
    },
    "id": "LKtr9k7-LG3k",
    "outputId": "14340519-02de-4c5f-95d4-cf1b8c068f67"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470feafa7bc1429e80f82f4211c2cdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "microaggressions_dataset = Dataset.from_dict({\n",
    "    'cleaned_text': df_micro['cleaned_text'].fillna('').tolist(),\n",
    "    'label': y_micro_encoded.tolist()\n",
    "})\n",
    "\n",
    "preprocessed_microaggressions_data = microaggressions_dataset.map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    fn_kwargs={'tokenizer': bert_tokenizer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "SP6bHTUnLJjC",
    "outputId": "6b230148-5f6c-4640-fba0-7f090bf4bdc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sequential Model Accuracy: 0.5965\n",
      "\n",
      "Classification Report (Sequential):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  Normal Speech       0.56      0.81      0.66        84\n",
      "Microaggression       0.68      0.39      0.50        87\n",
      "\n",
      "       accuracy                           0.60       171\n",
      "      macro avg       0.62      0.60      0.58       171\n",
      "   weighted avg       0.62      0.60      0.58       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "micro_predictions_sequential = sarcasm_trainer.predict(preprocessed_microaggressions_data)\n",
    "y_micro_pred_sequential = np.argmax(micro_predictions_sequential.predictions, axis=1)\n",
    "micro_accuracy_sequential = accuracy_score(y_micro_encoded, y_micro_pred_sequential)\n",
    "\n",
    "print(f\"\\n Sequential Model Accuracy: {micro_accuracy_sequential:.4f}\")\n",
    "print(\"\\nClassification Report (Sequential):\")\n",
    "print(classification_report(\n",
    "    y_micro_encoded,\n",
    "    y_micro_pred_sequential,\n",
    "    target_names=['Normal Speech', 'Microaggression']\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}