{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Z8LeEMJRTz"
   },
   "source": [
    "### Bert Base Cased ###\n",
    "\n",
    "Train and test on ISHate dataset, then evlauate with the microaggressions dataset. Following example from previous assigments & notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqB3DQfxJUKI"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q torchinfo\n",
    "!pip install -U -q datasets\n",
    "!pip install -q evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jjqPdqM-WI3",
    "outputId": "0577ecc0-3e89-42d2-f739-c7d711d0f01c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAwK53ldJVm3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "ee45a4920a664c1bb3cfc4d88e7d15f3",
      "9eee4ec33b6d40fb8990851f34b9dfe5",
      "0723f61ef324426e8b6fb25c62952b77",
      "9534bdad18cf4da8b2ad38f305866fc2",
      "f9fc366e7a4f453b901c7a847b27b1ea",
      "0be47ce2af094a53bb76748f0be22ea1",
      "4051e4a17290480cab38286e8b72e0a1",
      "a9d16f73e6ed485bb042ae8ee1d61a2c",
      "f8a2a6c3c5784b9d90137fb95c0811f9",
      "2223866ddcda4c07ae9dcb472ba5c0af",
      "73f967cafa984f6ca902c95c7e21e694",
      "9aaa24ecbfa84fa1aee133127bd765ed",
      "df9ba06e28bf4817b36605061ab0eeb8",
      "2d7bda147c6544afb8b6e2d141224f33",
      "fd6deae35c0e4fa9b103e565cb017415",
      "c8cac5e8ebca495495f7f59ef3075bd2",
      "7de07d190fb5424881536b1e5485e9ab",
      "461947ffd65a490fa8d293c0ad965da4",
      "8bef4574a79f460685e3d20547f661d7",
      "89639ec8b31947459a22b2b3636d7079",
      "e369c09cfe9349c39610f9836576a034",
      "b0e959c2d9444dce949686ebd00a0861"
     ]
    },
    "outputId": "9dd0f9f4-3608-4771-a639-8969d4678be2"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee45a4920a664c1bb3cfc4d88e7d15f3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9aaa24ecbfa84fa1aee133127bd765ed"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "import evaluate\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "splits = {\n",
    "    'train': 'ishate_train.parquet.gzip',\n",
    "    'validation': 'ishate_dev.parquet.gzip',\n",
    "    'test': 'ishate_test.parquet.gzip'\n",
    "}\n",
    "\n",
    "df_train = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"train\"])\n",
    "df_val = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"validation\"])\n",
    "df_test = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"test\"])\n",
    "max_sequence_length = 128\n",
    "\n",
    "# create DatasetDict\n",
    "ishate_dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"validation\": Dataset.from_pandas(df_val),\n",
    "    \"test\": Dataset.from_pandas(df_test)\n",
    "})\n",
    "\n",
    "# Encode labels, similar to how we did above for the CNN.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(ishate_dataset['train']['hateful_layer'])\n",
    "y_val_encoded = label_encoder.transform(ishate_dataset['validation']['hateful_layer'])\n",
    "y_test_encoded = label_encoder.transform(ishate_dataset['test']['hateful_layer'])\n",
    "ishate_train_data = ishate_dataset['train'].add_column('label', y_train_encoded.tolist())\n",
    "ishate_val_data = ishate_dataset['validation'].add_column('label', y_val_encoded.tolist())\n",
    "ishate_test_data = ishate_dataset['test'].add_column('label', y_test_encoded.tolist())\n",
    "\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "    # Ensure text is a list of strings\n",
    "    text = data['cleaned_text']\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "            text,\n",
    "            max_length=max_sequence_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True\n",
    "            # return_tensors=\"pt\"\n",
    "    )\n",
    "    return encoded\n",
    "\n",
    "\n",
    "metric = evaluate.load('accuracy')\n",
    "f1  = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        **metric.compute(predictions=predictions, references=labels),\n",
    "        \"f1_macro\": f1.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5HqLZ16JX1F"
   },
   "outputs": [],
   "source": [
    "def fine_tune_classification_model(classification_model,\n",
    "                                   tokenizer,\n",
    "                                   train_data,\n",
    "                                   dev_data,\n",
    "                                   batch_size = 16,\n",
    "                                   num_epochs = 2,\n",
    "                                   learning_rate=2e-5):\n",
    "    \"\"\"\n",
    "    Preprocess the data using the given tokenizer (we've give you the code for that part).\n",
    "    Create the training arguments and trainer for the given model and data (write your code for that).\n",
    "    Then train it.\n",
    "    \"\"\"\n",
    "\n",
    "    preprocessed_train_data = train_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "    preprocessed_dev_data = dev_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "\n",
    "    # Referencing lesson 4 notebook & assignment 2 as an example:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=\"bert_ishate\",\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      per_device_eval_batch_size=batch_size,\n",
    "      num_train_epochs=num_epochs,\n",
    "      learning_rate=learning_rate,\n",
    "      eval_strategy=\"epoch\",\n",
    "      save_strategy=\"epoch\",\n",
    "      report_to='none',\n",
    "      load_best_model_at_end = True,\n",
    "      metric_for_best_model = \"f1_macro\",\n",
    "      seed = 42\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=classification_model,\n",
    "      args=training_args,\n",
    "      train_dataset=preprocessed_train_data,\n",
    "      eval_dataset=preprocessed_dev_data,\n",
    "      compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "7621eecdbd8342e1970eebcff72df123",
      "5e10a4b018364602a9b2d90d6bd9cd78",
      "c06dd64bf2b74bab87951cd6900f63d8",
      "73ca22d2ad7049cc813b79287d77053d",
      "5db3c4f8f6e04e4faaa888f038704582",
      "834b68927a214e9b981d9893c4432630",
      "f98672186c374c22b1614d7bb7591ccd",
      "c2a2c9533ee24585b864ff136f8e24b5",
      "c22b11d7dbd8438395aa8ec264244d8e",
      "88a4e463e2ce48b49280374c46e290e6",
      "b5fb4c9c8475458db543f662eaf92b7b",
      "17391d9c66d14b4ab9d37a4c399f948c",
      "5877c6590a1a42b1887bac93dc01e162",
      "262482107fb24ea18740f5947bbf841f",
      "28a2e56694f8482ca40586a59c17dc2c",
      "c9df8ab4b02046c6ba5775051b29b71b",
      "cc84c8e84eee49bb856f172a1c605178",
      "9d33ad665ec5453c8bb42cd1c395f983",
      "dad0eeb07b4b46e6860b461a03803f70",
      "516cf12900e14acdaddb235d4869fc2b",
      "4a6967f6c8ab4ebc8bf8d95096be58e6",
      "727dbab86d504b72a2e693da10bc9438",
      "79856dd96a7c403da70fcf74f156cc6c",
      "f131244e86e44c0a948ea93c00f163d3",
      "4612198353d246718ad71b22a3675539",
      "f088fb0e0036430f95868cdda80a3603",
      "0689b79482674c92b935ac9644c6a026",
      "01a85f875a554c91805e60ffea460163",
      "c57045cefa46406ab0bb164a11eacd3a",
      "adcd52c0bde647358936422e4bfb4216",
      "dc50dd0272474f51a5fed9183537f02f",
      "b54812ae24074baca9016ce28affc24e",
      "3013540440c446c4821467479bbf5218",
      "343761afd2e640e2bb33bee7c4f4dcd9",
      "1f4ce2f444b54a90a5ab818094507cdc",
      "15bbe321b319429e96482b5cc5102554",
      "7e1d8d1d3f384161b79cf306b9fef25b",
      "c40b14fe163f4424a2973db11722b8f7",
      "dc27dc6f4ab74702813d9be62d132f2b",
      "8ac575532a0c4921b0f035675e2ade8d",
      "f9421d1086b549f38db2ea6119cdc0f5",
      "250df1c6ff194d9293529a20b2f24278",
      "8039580dbced4d1db297394b81ab49a6",
      "4d036759dd8d494d90c894ea0cafae9d",
      "b40fd10bc9ff4fc28ab7c26738ff39c9",
      "66d76ae8612e41d792af2bddce2990c0",
      "8f64d05161ac4499b79e0aa73d79fc81",
      "c7f07feae63541878a9b919f4580af8f",
      "538a6ea349f6408ca2aaaab5ebaa1771",
      "467d47161f3e4a61a9be1a753ec5304e",
      "d8100e4ee5fc4f9d87d1b4c93c465bdc",
      "bb05f677b7a14cb38b65a8913ed2bfb9",
      "3184a786c13143548912efac9cd2ef72",
      "0a9e673f02404717abe2c78fe2f91b63",
      "d315abd98437486ab6943aa070751faf"
     ]
    },
    "id": "_bZ_FlMuJauu",
    "outputId": "e0c6f825-1cc1-41e0-9807-78a5c88d1ba6"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7621eecdbd8342e1970eebcff72df123"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17391d9c66d14b4ab9d37a4c399f948c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79856dd96a7c403da70fcf74f156cc6c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "343761afd2e640e2bb33bee7c4f4dcd9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b40fd10bc9ff4fc28ab7c26738ff39c9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_name = \"bert-base-cased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_name)\n",
    "bert_classification_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_name, num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "9133fbe99f81401cb3fcb37e793c169b",
      "89b6f15a5a754aabb6f9db95bd6ea611",
      "aec2bbf0325f47ba8af0478a8bfb6ebf",
      "bcbc520089614cba89ddf14f45fc1f9c",
      "bb6adc432bad48c9b75b585b192275e6",
      "f1a5b860118d4967b89974a580df26be",
      "3cfebb8740c542a693a390911f83c7b3",
      "cfdc028b2e474c838ed8b9f0c4a64019",
      "e9fd792a02104f93b593238b8ab4a233",
      "1a85e31767184b5e84fd4e2f54ce5f55",
      "1438c03a756947a78e1af8cd8c857198",
      "a5bffbad783d403181e1ff7fc286924f",
      "55723fe59f1f4125a4ac7cdf83735406",
      "ea00a5d41f5d4efb806371666d89d9b7",
      "a95beb0470c246dca470a795de2bc1d7",
      "f21788aebb96401da90550e6d71752de",
      "d98c072f2b2042088d1c9553194357a3",
      "528431ad69c146b9aa9d1fde467a6230",
      "ae55d21f2ae84961b56f80e538815406",
      "6737ccdd89ec47d29ad76a597d682c9f",
      "4ed38dcd222a40a189519d65c26bb13c",
      "4839e9c73fae4ec888a024c42b3fa90d"
     ]
    },
    "id": "rjxlbTLCJct0",
    "outputId": "bd0cccc7-7f3c-47ec-e919-2b3838802605"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/55023 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9133fbe99f81401cb3fcb37e793c169b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4367 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5bffbad783d403181e1ff7fc286924f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6878' max='6878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6878/6878 41:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.598428</td>\n",
       "      <td>0.855278</td>\n",
       "      <td>0.844107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.678873</td>\n",
       "      <td>0.855736</td>\n",
       "      <td>0.849203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "bert_base_cased_trainer = fine_tune_classification_model(bert_classification_model, bert_tokenizer, ishate_train_data, ishate_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "36b789ccd0ad4eb59a5f79c0a5e024d0",
      "d3345ace50084603b4e4c623c8fd2343",
      "0e1f91098295422b98a326638b6a2ca7",
      "d5bc5d398e0e41ce9df28e8bfafc27a8",
      "2b213ab12e2a4a228faddf64bdb762cc",
      "ecc10815c94941029a48504fc5ba7622",
      "f15bfb31776645fb9095b86b5be0e485",
      "cf486f6026e647bcae8745406af4dcd7",
      "2bab8868259a454bada67eda276384e9",
      "406e52c706714209ad8876e11c6d3d84",
      "fe8b246cb0f9442b9f1c716f5f277b38"
     ]
    },
    "id": "Ky1oiQ4cJeZs",
    "outputId": "80e6c1e7-e212-438a-8c5a-e3aaefefebb0"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4368 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36b789ccd0ad4eb59a5f79c0a5e024d0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test Accuracy: 0.8636\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HS       0.81      0.85      0.83      1687\n",
      "      Non-HS       0.90      0.87      0.89      2681\n",
      "\n",
      "    accuracy                           0.86      4368\n",
      "   macro avg       0.85      0.86      0.86      4368\n",
      "weighted avg       0.87      0.86      0.86      4368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_test_data = ishate_test_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': bert_tokenizer})\n",
    "predictions = bert_base_cased_trainer.predict(preprocessed_test_data)\n",
    "preprocessed_test_pred = np.argmax(predictions.predictions, axis=1)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "test_accuracy = accuracy_score(y_test_encoded, preprocessed_test_pred)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, preprocessed_test_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsLiietNE1jo"
   },
   "source": [
    "### Now train on iSarcasm Eval: ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "30ce456b71f24c11963d47674a65f216",
      "91239505515b49acb93c7726cbc1cb6b",
      "4a01d2a63d3d45488f31e13efcd2a27b",
      "d79db6498b42426db48f9d682054c0ea",
      "3e9c7804f0c541eab8f4338f16f018ca",
      "11961c6f837e4ef587d37ad18f5add4b",
      "0a40267188d54c408d01dd52a5f01c44",
      "5df2210b16ff4352aaab23e8ba7b4994",
      "a5b0328d005547219f2ee1e7161fc913",
      "44d5d0bb3d094cb8a33cc6c1f6031f81",
      "1ac1c8d956c4410d812bdbd020d482dd",
      "d453cf162619491387d1cf9aaccd5a78",
      "f5861a9df5524b798e589aafa9a78ba6",
      "82be300ba7d047d993366250786a1d33",
      "45f12f343c004ab5b3f6c1de4555865a",
      "a8570cb5de794fc9a232ffa5a02b34a4",
      "0b033cf43d0540889aeb9eeba8496c8a",
      "a49e5927764b4c40ac67b5f581cb3954",
      "811bc399db9e4899b1f83760da5161d8",
      "41a98b5497e84b0d9226cc5459d60811",
      "972b9bdd95934759861a217d773b9017",
      "c1ed729af4bf42c1b9bad73b8c61c4e0"
     ]
    },
    "id": "7HWxDa6hE6sJ",
    "outputId": "6cc93727-cf35-4a3e-da58-255c2446900b"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2774 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30ce456b71f24c11963d47674a65f216"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d453cf162619491387d1cf9aaccd5a78"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [348/348 02:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.559263</td>\n",
       "      <td>0.750720</td>\n",
       "      <td>0.428807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.557374</td>\n",
       "      <td>0.750720</td>\n",
       "      <td>0.434403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "isarc_train_df = pd.read_csv('/content/drive/MyDrive/W266_Fall2025_Neeha_Kotte/final_project/train_EN_iSarcasmEval.csv')\n",
    "isarc_test_df = pd.read_csv('/content/drive/MyDrive/W266_Fall2025_Neeha_Kotte/final_project/task_A_En_test.csv')\n",
    "isarc_test_df.head()\n",
    "\n",
    "isarc_train_cleaned_df = isarc_train_df.copy()\n",
    "isarc_train_cleaned_df['cleaned_text'] = isarc_train_df['tweet']\n",
    "isarc_train_cleaned_df['label'] = isarc_train_df['sarcastic']\n",
    "\n",
    "isarc_test_cleaned_df = isarc_test_df.copy()\n",
    "isarc_test_cleaned_df['cleaned_text'] = isarc_test_df['text']\n",
    "isarc_test_cleaned_df['label'] = isarc_test_df['sarcastic']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "isarc_train_split, isarc_val_split = train_test_split(\n",
    "    isarc_train_cleaned_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=isarc_train_cleaned_df['label'] if 'label' in isarc_train_cleaned_df.columns else None\n",
    ")\n",
    "\n",
    "isarc_train_split['cleaned_text'] = isarc_train_split['cleaned_text'].fillna('').astype(str)\n",
    "isarc_val_split['cleaned_text'] = isarc_val_split['cleaned_text'].fillna('').astype(str)\n",
    "isarc_test_cleaned_df['cleaned_text'] = isarc_test_cleaned_df['cleaned_text'].fillna('').astype(str)\n",
    "\n",
    "\n",
    "isarc_train_dataset = Dataset.from_pandas(isarc_train_split[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "isarc_val_dataset = Dataset.from_pandas(isarc_val_split[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "isarc_test_dataset = Dataset.from_pandas(isarc_test_cleaned_df[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "\n",
    "sarcasm_trainer = fine_tune_classification_model(\n",
    "    bert_base_cased_trainer.model,\n",
    "    bert_tokenizer,\n",
    "    isarc_train_dataset,\n",
    "    isarc_val_dataset,\n",
    "    batch_size=16,\n",
    "    num_epochs=2,\n",
    "   learning_rate=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "cR0hdG9B7zpY",
    "outputId": "1f6a4862-911c-47f7-fa14-293335925e98"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "ISHate Test Performance:\n",
      "  Before sarcasm training: 0.8636\n",
      "  After sarcasm training:  0.4350\n",
      "  Change:                  -0.4286\n"
     ]
    }
   ],
   "source": [
    "# Check that the model can still detect hate speech, even after training on sarcasm\n",
    "predictions_after_sarc = sarcasm_trainer.predict(preprocessed_test_data)\n",
    "y_test_pred_after = np.argmax(predictions_after_sarc.predictions, axis=1)\n",
    "test_accuracy_after = accuracy_score(y_test_encoded, y_test_pred_after)\n",
    "\n",
    "print(f\"\\nISHate Test Performance:\")\n",
    "print(f\"  Before sarcasm training: {test_accuracy:.4f}\")\n",
    "print(f\"  After sarcasm training:  {test_accuracy_after:.4f}\")\n",
    "print(f\"  Change:                  {(test_accuracy_after - test_accuracy):+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWI-qFXhJfrA"
   },
   "source": [
    "### Microaggressions Evaluation:\n",
    "Now trying with the balanced selfMA dataset Carlos created.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "balanced_selfMA_ds = load_from_disk(\"/content/drive/MyDrive/266_project/balanced_selfMA_ds\")\n",
    "balanced_selfMA_ds = balanced_selfMA_ds.rename_column('text', 'cleaned_text')\n",
    "\n",
    "\n",
    "microagg_trainer = fine_tune_classification_model(\n",
    "    sarcasm_trainer.model,  # Continue from the sarcasm model\n",
    "    bert_tokenizer,\n",
    "    balanced_selfMA_ds['train'],\n",
    "    balanced_selfMA_ds['validation'],\n",
    "    batch_size=16,\n",
    "    num_epochs=3,\n",
    "    learning_rate=1e-5\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233,
     "referenced_widgets": [
      "1e30103246de49c2a5a0aeec4aa57d16",
      "2b031975e57f482899421876ac8cda1a",
      "e5b64ff69b94483cb06c8b2a7e162884",
      "583ec8a4b84b44849f6e2f16a3222039",
      "ce6095dab550472ea3b851a02130cb8b",
      "a947e20cccf64792a3a0a2f9951b0462",
      "c80ab5cd38a640e1b6f07347490685f4",
      "8a6dfdf4378c4e9eb20ae562031975c6",
      "f3ccee64bdac4384b0a5402b6451742b",
      "c41328945a3d48988745906428e90de3",
      "1cb739ab159c42be9e7bc77e589cf445",
      "ecf02be2cc264b5f9286b0839243d11c",
      "616a12c887a34db8879cb8798d7b368f",
      "1269ac349b0849fbad6c1ee69208fd9f",
      "8c7636588547489ab02a29a7e03c724f",
      "a84cc5018054469fa2190572f1f7be6e",
      "cbd91d899cd1433e85fbc53ab60b24c3",
      "55117943765343d5a74657ea7d934204",
      "70332e629f4942b9b0fb556befb53c2f",
      "edfd690c635749acbda7ab16eb899b45",
      "fa48604dcce944a0ac69155ce7b06d58",
      "6a5f8e179dd14545bb4f5d08a45a16b5"
     ]
    },
    "id": "VkB2Zanm7aOH",
    "outputId": "65a4f0f6-5929-4e2b-d82b-646270611e5d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4354 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e30103246de49c2a5a0aeec4aa57d16"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/544 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ecf02be2cc264b5f9286b0839243d11c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='819' max='819' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [819/819 05:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.153605</td>\n",
       "      <td>0.959559</td>\n",
       "      <td>0.959539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.110443</td>\n",
       "      <td>0.972426</td>\n",
       "      <td>0.972426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.112901</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.970588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "preprocessed_microagg_test = balanced_selfMA_ds['test'].map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    fn_kwargs={'tokenizer': bert_tokenizer}\n",
    ")\n",
    "\n",
    "microagg_predictions = microagg_trainer.predict(preprocessed_microagg_test)\n",
    "y_microagg_pred = np.argmax(microagg_predictions.predictions, axis=1)\n",
    "y_microagg_test = balanced_selfMA_ds['test']['label']\n",
    "\n",
    "microagg_accuracy = accuracy_score(y_microagg_test, y_microagg_pred)\n",
    "\n",
    "print(f\"\\nMicroaggressions Test Accuracy (Sequential Training): {microagg_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_microagg_test,\n",
    "    y_microagg_pred,\n",
    "    target_names=['Non-Microaggression', 'Microaggression']\n",
    "))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "f56ca09ebaa545a9a0489d7b42aab2fd",
      "d034aab75e404a22946a7666cc010749",
      "65440a26907347f4bd2b6eeeff905da7",
      "d7c3085c6772480aadb4281a3043e8c5",
      "ad709fa3eb704c47a79a0b0450d4811b",
      "0d1eec097a81433c88eb220927295c21",
      "87b4b190e8ae4846a78c4881b4c4edcd",
      "b017863ce9984a32bb99f1823aaf6333",
      "789f0147a63547909b917e07610f1569",
      "a111618d2a0d4337b950aefd52a94773",
      "027828021db840a7b57d831dd9949ccb"
     ]
    },
    "id": "vMSrgPbNiZwA",
    "outputId": "1142a138-4558-4423-fad9-2c1bd0a48e31"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/546 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f56ca09ebaa545a9a0489d7b42aab2fd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Microaggressions Test Accuracy (Sequential Training): 0.9744\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Non-Microaggression       0.98      0.97      0.97       273\n",
      "    Microaggression       0.97      0.98      0.97       273\n",
      "\n",
      "           accuracy                           0.97       546\n",
      "          macro avg       0.97      0.97      0.97       546\n",
      "       weighted avg       0.97      0.97      0.97       546\n",
      "\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}