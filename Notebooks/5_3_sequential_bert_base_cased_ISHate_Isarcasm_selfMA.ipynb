{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Z8LeEMJRTz"
   },
   "source": [
    "### Bert Base Cased ###\n",
    "\n",
    "Train and test on ISHate dataset, then evlauate with the microaggressions dataset. Following example from previous assigments & notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqB3DQfxJUKI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c43096f0-183c-4d96-bdf7-87b8e399aa0d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q torchinfo\n",
    "!pip install -U -q datasets\n",
    "!pip install -q evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jjqPdqM-WI3",
    "outputId": "9dfb89b4-7cc9-4836-8877-40179ec7a71d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAwK53ldJVm3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "c7df38ed9fd249e39723a6009948e212",
      "512113d877e446a3afc582458ad4f09b",
      "95f7f85214d44493ad3e0982cfc17dee",
      "f6e1f0da4c924211ba54ef4010141fc6",
      "abcc26ae50894610a02d6f9fc99d2a0a",
      "ab619f165cee4e8d9af41779639ef023",
      "36e9a18aa1d54af28c5f0d1c2e8ee968",
      "392169024cb84755865a16298be0ea72",
      "a851db2cd47e482fbf40bdc957e3a56a",
      "dde3ca0f998b4c51bd1577df985cdac2",
      "2e0c1d563fef4e598c628b856d7daa49",
      "c2cdf184810f4f1c9a790f496dedfa9c",
      "db87c01b19b0402d8bede8a8de4f03f7",
      "0ef5c783e8254d919c5b253ca132e649",
      "a8337bdd182d42209fe43935929b5b6e",
      "bcbd990a2b0d44b688d4032b184f1779",
      "56e4c9a5c5f3483385414441bf8622a1",
      "0f2e9c7b81d04ebf9aff30c11be81906",
      "8402308d87bc4639a730b0a7e27696f9",
      "feb0f0d0c1f54456934cf83631f81fd4",
      "4ed72ba3b1794497a3ef097dc277105c",
      "b17648d11b9145d3b01f8769792ffcef"
     ]
    },
    "outputId": "4ab53193-2950-400f-a1d8-42904f18fa9b"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7df38ed9fd249e39723a6009948e212"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2cdf184810f4f1c9a790f496dedfa9c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "import evaluate\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "splits = {\n",
    "    'train': 'ishate_train.parquet.gzip',\n",
    "    'validation': 'ishate_dev.parquet.gzip',\n",
    "    'test': 'ishate_test.parquet.gzip'\n",
    "}\n",
    "\n",
    "df_train = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"train\"])\n",
    "df_val = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"validation\"])\n",
    "df_test = pd.read_parquet(\"hf://datasets/BenjaminOcampo/ISHate/\" + splits[\"test\"])\n",
    "max_sequence_length = 128\n",
    "\n",
    "# create DatasetDict\n",
    "ishate_dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"validation\": Dataset.from_pandas(df_val),\n",
    "    \"test\": Dataset.from_pandas(df_test)\n",
    "})\n",
    "\n",
    "# Encode labels, similar to how we did above for the CNN.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(ishate_dataset['train']['hateful_layer'])\n",
    "y_val_encoded = label_encoder.transform(ishate_dataset['validation']['hateful_layer'])\n",
    "y_test_encoded = label_encoder.transform(ishate_dataset['test']['hateful_layer'])\n",
    "ishate_train_data = ishate_dataset['train'].add_column('label', y_train_encoded.tolist())\n",
    "ishate_val_data = ishate_dataset['validation'].add_column('label', y_val_encoded.tolist())\n",
    "ishate_test_data = ishate_dataset['test'].add_column('label', y_test_encoded.tolist())\n",
    "\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "    # Ensure text is a list of strings\n",
    "    text = data['cleaned_text']\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "            text,\n",
    "            max_length=max_sequence_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True\n",
    "            # return_tensors=\"pt\"\n",
    "    )\n",
    "    return encoded\n",
    "\n",
    "\n",
    "metric = evaluate.load('accuracy')\n",
    "f1  = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        **metric.compute(predictions=predictions, references=labels),\n",
    "        \"f1_macro\": f1.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5HqLZ16JX1F"
   },
   "outputs": [],
   "source": [
    "def fine_tune_classification_model(classification_model,\n",
    "                                   tokenizer,\n",
    "                                   train_data,\n",
    "                                   dev_data,\n",
    "                                   batch_size = 16,\n",
    "                                   num_epochs = 2,\n",
    "                                   learning_rate=2e-5):\n",
    "    \"\"\"\n",
    "    Preprocess the data using the given tokenizer (we've give you the code for that part).\n",
    "    Create the training arguments and trainer for the given model and data (write your code for that).\n",
    "    Then train it.\n",
    "    \"\"\"\n",
    "\n",
    "    preprocessed_train_data = train_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "    preprocessed_dev_data = dev_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "\n",
    "    # Referencing lesson 4 notebook & assignment 2 as an example:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=\"bert_ishate\",\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      per_device_eval_batch_size=batch_size,\n",
    "      num_train_epochs=num_epochs,\n",
    "      learning_rate=learning_rate,\n",
    "      eval_strategy=\"epoch\",\n",
    "      save_strategy=\"epoch\",\n",
    "      report_to='none',\n",
    "      load_best_model_at_end = True,\n",
    "      metric_for_best_model = \"f1_macro\",\n",
    "      seed = 42\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=classification_model,\n",
    "      args=training_args,\n",
    "      train_dataset=preprocessed_train_data,\n",
    "      eval_dataset=preprocessed_dev_data,\n",
    "      compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "71739b6f187f4ea0840e4ccab2f154a1",
      "6fd662979d334fa1895a993dd619d34e",
      "5ca45470a84a433081f01c4297914415",
      "81e74cb5f25b4d509426317956af108e",
      "1fcdc9ba5b9643c7abb7d0ea2b2c30b3",
      "e2065316879344b89d7958a0cc7d13ad",
      "df5da7afcd4f4c9a89c9b154adc6eb47",
      "34545c15c0234f5486c0eca5857fde46",
      "cf652883d1c349058214a932946e4462",
      "f9d32dcdcd0f4d81b884a514b79f98e8",
      "c9abdd10a4a2458b910aa9c0e59e4b61",
      "f869ca622a09454f947369b9804ddde9",
      "31a97ea6cff441dd911f3907309eb296",
      "afd6060aca9e470fb1254cb6f229615a",
      "80100e4a54574cafba1459e65ffd6aaf",
      "922a78906039401ab2bedd50c0e2295e",
      "afa3b46ca4a147f5a45f8a697fe7cf89",
      "df6ce97b20424ca3ba1d2c07b14428ba",
      "81f789c9ee884bef891088304969f921",
      "f2ff0c069baa4949835497d82993ffa1",
      "5661a5268c434a619652f409f7d0c895",
      "8da2356bfdca4912861a962be0ca7b6e",
      "4acdc5b4fdd94f67b6620054cec89c98",
      "e03f6f60dfbb4ecf94525583ecdf8e69",
      "ced2344679d94e1995b905a13ac0d2e9",
      "1d1030984dda4df989b3e5afc3d47741",
      "41e1ff5cb4e2434ab5be48582f22ffd4",
      "d6cfe9d4c83c4fd18abd801ee8f8cf37",
      "4798955ce7b54de1aedc8962481baabb",
      "8c40f211a441460eafd44b7d1eeb31ad",
      "25596b164dae49fbb582821734c43c45",
      "04681189a49746aba1098ee69ba07ed1",
      "303ad02264f94fbabe0adf3fb84c8daa",
      "c0f24801bea940d680311cd29dc67e0f",
      "a46aa42ddb094eb4bc5822859b056141",
      "8835eb5e7efa44bfb6f97a9e62d56c72",
      "a8324355afe74abfb1a97ceed0aa5520",
      "8880495a217f4748b044cab5cbb5bb77",
      "ad88dacf60c24e629ed258912a1f4c10",
      "15a7851aed3d4a6ca61bcf311d381641",
      "6cf16c2cf77a44bf86be2db3c9e9e165",
      "a545e23648724d5892c1f08bea04a24a",
      "02f96135441c44afb639325ace18a430",
      "f9a3c8fd82094515a0e8f3dc9be07521",
      "261fef41df82442984957b1ea365aa72",
      "80153d5f9c194a2b87824993dcc742ef",
      "b64c5dca449c4ffc8ecf877ef68ac6ed",
      "42deae2b61db4c31b3562ebad9357b7b",
      "c2e8fbb3e7274755b3096a20ea3587ca",
      "57256999488d4cbab9176d6ebefb79cb",
      "7559dfc2645d495793dfd9f0e9be9335",
      "7bedf01b0f3a4dbc8ef78ff33d37b4a1",
      "b16e25f7a37648c397e65098e12c8b0d",
      "c4a40110fd3842dcb93c99e8211ce503",
      "392caa8daa334f28919246d61749cee3"
     ]
    },
    "id": "_bZ_FlMuJauu",
    "outputId": "d93fbead-c7b8-400a-dd43-10eb69ded961"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71739b6f187f4ea0840e4ccab2f154a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f869ca622a09454f947369b9804ddde9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4acdc5b4fdd94f67b6620054cec89c98"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0f24801bea940d680311cd29dc67e0f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "261fef41df82442984957b1ea365aa72"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_name = \"bert-base-cased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_name)\n",
    "bert_classification_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_name, num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "7f533e6f84e24e8093ffea5d59e7511c",
      "aec0f685ad6c4ef98870c8f2233c454a",
      "5a47b49fb07b44278e5988e311d59868",
      "003afd20718a43f88f2d8447d1054c92",
      "49f84501ec004308b4488aa3af7da9c6",
      "19728250132c4e738a7fa122eae5e948",
      "8882e3ebed5540e589fe6208fd137d53",
      "a00b72d1825b4b428a630025634fd19e",
      "c0ce18c5a1f34970a96002b43cbe7859",
      "7b086a5ea1c44a44b06775d36e14577c",
      "054c42ecb2e04c6980ca3a693d832bcc",
      "4d7941ba3f174fbf9a5254fa107858e1",
      "b28c0a4ea5e74a6798d2747c03b8d3ac",
      "6f9d1488ab7047788ef98929051f8e5a",
      "389f89d1ade84094b67fab67ee3bd38d",
      "3555a05b1fb2436ab77b8185cedfa534",
      "30015d24a382496daf18628ac3b62e54",
      "d7c15c3a07de4353bed179b172c8f51e",
      "25aaa7a02d964ec8b113519026af9951",
      "23f7748dfc2847aa9c74c130a093f247",
      "fb074fbfb3a44e1c9b6f158446ee84e3",
      "2229e11e94b04681a6b30f3272b5de4f"
     ]
    },
    "id": "rjxlbTLCJct0",
    "outputId": "9250d140-9787-4d93-88cc-ec7f1e8826e9"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/55023 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f533e6f84e24e8093ffea5d59e7511c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4367 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d7941ba3f174fbf9a5254fa107858e1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6878' max='6878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6878/6878 40:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.402143</td>\n",
       "      <td>0.854591</td>\n",
       "      <td>0.841795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>0.489982</td>\n",
       "      <td>0.863751</td>\n",
       "      <td>0.856463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "bert_base_cased_trainer = fine_tune_classification_model(bert_classification_model, bert_tokenizer, ishate_train_data, ishate_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "c349a1144e044d259af7f6b039b56650",
      "4bf6276a0659460583f3577dfe68eb0c",
      "840b2c4c67154531af30719c5ae066a5",
      "c596f3f3a1c34e5f8d5fc56dc1317c32",
      "61119d3eb26a4e3a9828b4e4f8f0a62b",
      "6f4c9ef634ab455184ef15baccd6c388",
      "ef8c07ba05ce4c788f3bbee6ad8fc4a2",
      "3c75d7e035184e52b3eb4628a5d79f16",
      "eee00b4a33d34c48a5f571435da86aba",
      "ff1c76f63c5947c99a8f57c762f063d7",
      "dd1609de516f46e8906f24d77671ff42"
     ]
    },
    "id": "Ky1oiQ4cJeZs",
    "outputId": "1e8eb30f-bebd-4f5f-bae6-e4182858ab2a"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4368 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c349a1144e044d259af7f6b039b56650"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test Accuracy: 0.8690\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HS       0.83      0.84      0.83      1687\n",
      "      Non-HS       0.90      0.89      0.89      2681\n",
      "\n",
      "    accuracy                           0.87      4368\n",
      "   macro avg       0.86      0.86      0.86      4368\n",
      "weighted avg       0.87      0.87      0.87      4368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_test_data = ishate_test_data.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': bert_tokenizer})\n",
    "predictions = bert_base_cased_trainer.predict(preprocessed_test_data)\n",
    "preprocessed_test_pred = np.argmax(predictions.predictions, axis=1)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "test_accuracy = accuracy_score(y_test_encoded, preprocessed_test_pred)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, preprocessed_test_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "balanced_selfMA_ds = load_from_disk(\"/content/drive/MyDrive/266_project/balanced_selfMA_ds\")\n",
    "balanced_selfMA_ds = balanced_selfMA_ds.rename_column('text', 'cleaned_text')\n",
    "\n",
    "preprocessed_microagg_test = balanced_selfMA_ds['test'].map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    fn_kwargs={'tokenizer': bert_tokenizer}\n",
    ")\n",
    "\n",
    "microagg_predictions = bert_base_cased_trainer.predict(preprocessed_microagg_test)\n",
    "y_microagg_pred = np.argmax(microagg_predictions.predictions, axis=1)\n",
    "y_microagg_test = balanced_selfMA_ds['test']['label']\n",
    "\n",
    "microagg_accuracy = accuracy_score(y_microagg_test, y_microagg_pred)\n",
    "\n",
    "print(f\"\\nMicroaggressions Test Accuracy (Sequential Training): {microagg_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_microagg_test,\n",
    "    y_microagg_pred,\n",
    "    target_names=['Non-Microaggression', 'Microaggression']\n",
    "))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "acRtgIEv_EdE",
    "outputId": "8f91140f-692c-4daa-b5c1-a772fecccf80"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Microaggressions Test Accuracy (Sequential Training): 0.3498\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Non-Microaggression       0.21      0.11      0.14       273\n",
      "    Microaggression       0.40      0.59      0.48       273\n",
      "\n",
      "           accuracy                           0.35       546\n",
      "          macro avg       0.30      0.35      0.31       546\n",
      "       weighted avg       0.30      0.35      0.31       546\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsLiietNE1jo"
   },
   "source": [
    "### Now train on iSarcasm Eval: ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "df443f934ad34fabbb60c31f4fcd46cb",
      "a9ff550cce504646a766c42813af0f2a",
      "464db3a4c77e4d6ab16e273440e69b64",
      "73472b63fe4140ac9eca3536a00d9c6f",
      "29bef5ceb97740dd9a907b6fbea13edf",
      "60146d25e0f74c00a9f2023a289590de",
      "71254f86872e44dbaa21f9bed6e3bb00",
      "1c019842e0eb4ba7a8e979a1f1b3974e",
      "1da309ea11db4c459e0c7ff9d811e5a8",
      "69480c1195754425bb373b1da93efcf5",
      "1caab53e4db94a8a98b8ad9eed14a030",
      "251a09058900444e99ca3dad66633a4f",
      "c3c8a027217c4a7297518c62643e4abf",
      "ef13fe5f85aa477aae4dc9db897af60b",
      "660167e273c649b1863df2a023451196",
      "30721b0243e1434b9274f93b82701e76",
      "6a6a1aea2289464dba48f5db3549442c",
      "f6214a066b214a67ad7465818601d7cf",
      "4b7e0f9df3804955ab6c79a856965af6",
      "828f25cfb3224b7393e9225cc47266ab",
      "714a4efdafaa4f00b2d102f084899145",
      "b13d05599ef34ce98db57732f40edf55"
     ]
    },
    "id": "7HWxDa6hE6sJ",
    "outputId": "f2028520-5562-4cb0-b0cb-68c770efad91"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2774 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df443f934ad34fabbb60c31f4fcd46cb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "251a09058900444e99ca3dad66633a4f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [348/348 02:52, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.562629</td>\n",
       "      <td>0.750720</td>\n",
       "      <td>0.428807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.564683</td>\n",
       "      <td>0.749280</td>\n",
       "      <td>0.428336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "isarc_train_df = pd.read_csv('/content/drive/MyDrive/W266_Fall2025_Neeha_Kotte/final_project/train_EN_iSarcasmEval.csv')\n",
    "isarc_test_df = pd.read_csv('/content/drive/MyDrive/W266_Fall2025_Neeha_Kotte/final_project/task_A_En_test.csv')\n",
    "isarc_test_df.head()\n",
    "\n",
    "isarc_train_cleaned_df = isarc_train_df.copy()\n",
    "isarc_train_cleaned_df['cleaned_text'] = isarc_train_df['tweet']\n",
    "isarc_train_cleaned_df['label'] = isarc_train_df['sarcastic']\n",
    "\n",
    "isarc_test_cleaned_df = isarc_test_df.copy()\n",
    "isarc_test_cleaned_df['cleaned_text'] = isarc_test_df['text']\n",
    "isarc_test_cleaned_df['label'] = isarc_test_df['sarcastic']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "isarc_train_split, isarc_val_split = train_test_split(\n",
    "    isarc_train_cleaned_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=isarc_train_cleaned_df['label'] if 'label' in isarc_train_cleaned_df.columns else None\n",
    ")\n",
    "\n",
    "isarc_train_split['cleaned_text'] = isarc_train_split['cleaned_text'].fillna('').astype(str)\n",
    "isarc_val_split['cleaned_text'] = isarc_val_split['cleaned_text'].fillna('').astype(str)\n",
    "isarc_test_cleaned_df['cleaned_text'] = isarc_test_cleaned_df['cleaned_text'].fillna('').astype(str)\n",
    "\n",
    "\n",
    "isarc_train_dataset = Dataset.from_pandas(isarc_train_split[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "isarc_val_dataset = Dataset.from_pandas(isarc_val_split[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "isarc_test_dataset = Dataset.from_pandas(isarc_test_cleaned_df[['cleaned_text', 'label']].reset_index(drop=True))\n",
    "\n",
    "sarcasm_trainer = fine_tune_classification_model(\n",
    "    bert_base_cased_trainer.model,\n",
    "    bert_tokenizer,\n",
    "    isarc_train_dataset,\n",
    "    isarc_val_dataset,\n",
    "    batch_size=16,\n",
    "    num_epochs=2,\n",
    "   learning_rate=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "cR0hdG9B7zpY",
    "outputId": "add7853c-1685-447d-e3b8-a3c78a7a65c8"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "ISHate Test Performance:\n",
      "  Before sarcasm training: 0.8690\n",
      "  After sarcasm training:  0.3933\n",
      "  Change:                  -0.4757\n"
     ]
    }
   ],
   "source": [
    "# Check that the model can still detect hate speech, even after training on sarcasm\n",
    "predictions_after_sarc = sarcasm_trainer.predict(preprocessed_test_data)\n",
    "y_test_pred_after = np.argmax(predictions_after_sarc.predictions, axis=1)\n",
    "test_accuracy_after = accuracy_score(y_test_encoded, y_test_pred_after)\n",
    "\n",
    "print(f\"\\nISHate Test Performance:\")\n",
    "print(f\"  Before sarcasm training: {test_accuracy:.4f}\")\n",
    "print(f\"  After sarcasm training:  {test_accuracy_after:.4f}\")\n",
    "print(f\"  Change:                  {(test_accuracy_after - test_accuracy):+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "balanced_selfMA_ds = load_from_disk(\"/content/drive/MyDrive/266_project/balanced_selfMA_ds\")\n",
    "balanced_selfMA_ds = balanced_selfMA_ds.rename_column('text', 'cleaned_text')\n",
    "\n",
    "preprocessed_microagg_test = balanced_selfMA_ds['test'].map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    fn_kwargs={'tokenizer': bert_tokenizer}\n",
    ")\n",
    "\n",
    "microagg_predictions = sarcasm_trainer.predict(preprocessed_microagg_test)\n",
    "y_microagg_pred = np.argmax(microagg_predictions.predictions, axis=1)\n",
    "y_microagg_test = balanced_selfMA_ds['test']['label']\n",
    "\n",
    "microagg_accuracy = accuracy_score(y_microagg_test, y_microagg_pred)\n",
    "\n",
    "print(f\"\\nMicroaggressions Test Accuracy (Sequential Training): {microagg_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_microagg_test,\n",
    "    y_microagg_pred,\n",
    "    target_names=['Non-Microaggression', 'Microaggression']\n",
    "))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "0eRhzNRS_Wuo",
    "outputId": "d764c2a5-985e-40e6-df25-2373f3ce03c9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Microaggressions Test Accuracy (Sequential Training): 0.5000\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Non-Microaggression       0.50      1.00      0.67       273\n",
      "    Microaggression       0.00      0.00      0.00       273\n",
      "\n",
      "           accuracy                           0.50       546\n",
      "          macro avg       0.25      0.50      0.33       546\n",
      "       weighted avg       0.25      0.50      0.33       546\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWI-qFXhJfrA"
   },
   "source": [
    "### Microaggressions Evaluation:\n",
    "Now trying with the balanced selfMA dataset Carlos created.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "balanced_selfMA_ds = load_from_disk(\"/content/drive/MyDrive/266_project/balanced_selfMA_ds\")\n",
    "balanced_selfMA_ds = balanced_selfMA_ds.rename_column('text', 'cleaned_text')\n",
    "\n",
    "\n",
    "microagg_trainer = fine_tune_classification_model(\n",
    "    sarcasm_trainer.model,  # Continue from the sarcasm model\n",
    "    bert_tokenizer,\n",
    "    balanced_selfMA_ds['train'],\n",
    "    balanced_selfMA_ds['validation'],\n",
    "    batch_size=16,\n",
    "    num_epochs=3,\n",
    "    learning_rate=1e-5\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "VkB2Zanm7aOH",
    "outputId": "636b63ab-b68d-48ae-88c9-ad1e036a12cf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='819' max='819' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [819/819 08:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.134134</td>\n",
       "      <td>0.961397</td>\n",
       "      <td>0.961394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.112652</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.970585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.111845</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.970587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "preprocessed_microagg_test = balanced_selfMA_ds['test'].map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    fn_kwargs={'tokenizer': bert_tokenizer}\n",
    ")\n",
    "\n",
    "microagg_predictions = microagg_trainer.predict(preprocessed_microagg_test)\n",
    "y_microagg_pred = np.argmax(microagg_predictions.predictions, axis=1)\n",
    "y_microagg_test = balanced_selfMA_ds['test']['label']\n",
    "\n",
    "microagg_accuracy = accuracy_score(y_microagg_test, y_microagg_pred)\n",
    "\n",
    "print(f\"\\nMicroaggressions Test Accuracy (Sequential Training): {microagg_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_microagg_test,\n",
    "    y_microagg_pred,\n",
    "    target_names=['Non-Microaggression', 'Microaggression']\n",
    "))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "vMSrgPbNiZwA",
    "outputId": "13ca743b-0f0e-4feb-aed3-dc79c8e2a3f6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Microaggressions Test Accuracy (Sequential Training): 0.9853\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Non-Microaggression       0.99      0.99      0.99       273\n",
      "    Microaggression       0.99      0.99      0.99       273\n",
      "\n",
      "           accuracy                           0.99       546\n",
      "          macro avg       0.99      0.99      0.99       546\n",
      "       weighted avg       0.99      0.99      0.99       546\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross-Eval on Workplace MA ###"
   ],
   "metadata": {
    "id": "cZQdnkau9FF2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "micro_agg_url = \"https://huggingface.co/spaces/khanak27/microaggressionsdetector/resolve/main/micro_agg.csv\"\n",
    "# Try different encodings to handle Unicode issues\n",
    "encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1', 'utf-8-sig']\n",
    "\n",
    "df_micro = None\n",
    "for encoding in encodings_to_try:\n",
    "    try:\n",
    "        print(f\"Trying encoding: {encoding}\")\n",
    "        df_micro = pd.read_csv(micro_agg_url, encoding=encoding)\n",
    "        print(f\"✅ Successfully loaded with {encoding} encoding\")\n",
    "        break\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"❌ Failed with {encoding}: {str(e)[:100]}...\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Other error with {encoding}: {str(e)[:100]}...\")\n",
    "        continue\n",
    "\n",
    "if df_micro is None:\n",
    "    print(\"❌ Failed to load dataset with any encoding. Trying with error handling...\")\n",
    "    try:\n",
    "        df_micro = pd.read_csv(micro_agg_url, encoding='utf-8', encoding_errors='replace')\n",
    "        print(\"✅ Loaded with UTF-8 and error replacement\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Final attempt failed: {e}\")\n",
    "        raise\n",
    "\n",
    "df_micro['cleaned_text'] = df_micro['speech']\n",
    "workplace_microaggressions_dataset = Dataset.from_dict({\n",
    "    'cleaned_text': df_micro['cleaned_text'].fillna('').tolist(),\n",
    "    'label': df_micro['label'].tolist()\n",
    "})"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fh2qJyfe9Hzs",
    "outputId": "5775aefd-b99f-4da5-eb9b-35d4570d294b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trying encoding: utf-8\n",
      "❌ Failed with utf-8: 'utf-8' codec can't decode byte 0xe2 in position 17: invalid continuation byte...\n",
      "Trying encoding: latin-1\n",
      "✅ Successfully loaded with latin-1 encoding\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "preprocessed_workplaceMA_test_data = workplace_microaggressions_dataset.map(preprocess_data, batched=True, fn_kwargs={'tokenizer': bert_tokenizer})\n",
    "predictions = microagg_trainer.predict(preprocessed_workplaceMA_test_data)\n",
    "preprocessed_workplaceMA_pred_bert_base = np.argmax(predictions.predictions, axis=1)\n",
    "y_true_bert_base_workplaceMA = workplace_microaggressions_dataset['label']\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "test_accuracy_workplaceMA_bert_base = accuracy_score(y_true_bert_base_workplaceMA, preprocessed_workplaceMA_pred_bert_base)\n",
    "print(f\"\\nTest Accuracy WorkplaceMA: {test_accuracy_workplaceMA_bert_base:.4f}\")\n",
    "print(\"\\nClassification Report WorkplaceMA:\")\n",
    "print(classification_report(y_true_bert_base_workplaceMA, preprocessed_workplaceMA_pred_bert_base, target_names=['0: Non-aggressive/normal text', '1: Microaggression']))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "33ffc91ef9e24088aed207384865f237",
      "c7bb7b1abc314278a689974da1b32009",
      "afcd3a190d8e46789706019304cddb26",
      "60016494a3a349a58c7a9aeb16902e04",
      "b91a2357823b4d54ba605d0eef40ce6c",
      "2d858336a9304c9bba7b5f21099d1f30",
      "36a49b656b134c43b9ffe7a77b068b07",
      "a0398ccb22524833960967c6ada119f8",
      "8427e144a5fe41e480af0949a55c944f",
      "d16244f7c6764469ac89d399c581ccdb",
      "b9b4ae3d081f4f10857874e7ebfd4ec6"
     ]
    },
    "id": "qV07tKFH9QvL",
    "outputId": "f5319bef-dbe3-4dc9-ef68-b9848bc2858d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33ffc91ef9e24088aed207384865f237"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test Accuracy WorkplaceMA: 0.5205\n",
      "\n",
      "Classification Report WorkplaceMA:\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "0: Non-aggressive/normal text       0.51      1.00      0.68        87\n",
      "           1: Microaggression       1.00      0.02      0.05        84\n",
      "\n",
      "                     accuracy                           0.52       171\n",
      "                    macro avg       0.76      0.51      0.36       171\n",
      "                 weighted avg       0.75      0.52      0.37       171\n",
      "\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}