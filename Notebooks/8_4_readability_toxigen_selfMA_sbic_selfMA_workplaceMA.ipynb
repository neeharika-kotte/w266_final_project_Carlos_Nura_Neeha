{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Toxigen SelfMA ###"
      ],
      "metadata": {
        "id": "VuqqLFgWBH2Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm-h8z8BFgQW",
        "outputId": "5287f330-ed92-4e4c-a79b-0531c58e1e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚ùå Ratio = 0.59 < 0.70\n",
            "   Datasets are quite different stylistically.\n",
            "   Risk of model learning dataset artifacts rather than semantics.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from datasets import load_from_disk\n",
        "balanced_selfMA_ds = load_from_disk(\"/content/drive/MyDrive/266_project/balanced_selfMA_ds_toxigen_quote\")\n",
        "\n",
        "balanced_selfMA_ds = balanced_selfMA_ds.rename_column('text', 'cleaned_text')\n",
        "\n",
        "all_data = pd.concat([\n",
        "    balanced_selfMA_ds['train'].to_pandas(),\n",
        "    balanced_selfMA_ds['validation'].to_pandas(),\n",
        "    balanced_selfMA_ds['test'].to_pandas()\n",
        "])\n",
        "\n",
        "selfma_texts = all_data[all_data['label'] == 1]['cleaned_text'].tolist()  # All microaggressions = SelfMA\n",
        "toxigen_texts = all_data[all_data['label'].isin([0, 2])]['cleaned_text'].tolist()  # Benign + toxic = ToxiGen\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "all_texts = selfma_texts + toxigen_texts\n",
        "vectors = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "selfma_vectors = vectors[:len(selfma_texts)]\n",
        "toxigen_vectors = vectors[len(selfma_texts):]\n",
        "\n",
        "selfma_sim = np.mean(cosine_similarity(selfma_vectors, selfma_vectors))\n",
        "toxigen_sim = np.mean(cosine_similarity(toxigen_vectors, toxigen_vectors))\n",
        "cross_sim = np.mean(cosine_similarity(selfma_vectors, toxigen_vectors))\n",
        "\n",
        "avg_within = (selfma_sim + toxigen_sim) / 2\n",
        "ratio = cross_sim / avg_within\n",
        "\n",
        "if ratio > 0.85:\n",
        "    print(f\"‚úÖ Ratio = {ratio:.2f} > 0.85\")\n",
        "    print(\"   Datasets are VERY similar stylistically.\")\n",
        "    print(\"   Strong evidence that model is learning semantic patterns, not style.\")\n",
        "elif ratio > 0.70:\n",
        "    print(f\"‚ö†Ô∏è  Ratio = {ratio:.2f} (0.70-0.85)\")\n",
        "    print(\"   Datasets have moderate stylistic similarity.\")\n",
        "    print(\"   Model could be learning both semantics and some style.\")\n",
        "else:\n",
        "    print(f\"‚ùå Ratio = {ratio:.2f} < 0.70\")\n",
        "    print(\"   Datasets are quite different stylistically.\")\n",
        "    print(\"   Risk of model learning dataset artifacts rather than semantics.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_stats(texts, name):\n",
        "    \"\"\"Calculate basic statistics about text\"\"\"\n",
        "    lengths = [len(text.split()) for text in texts]\n",
        "    char_lengths = [len(text) for text in texts]\n",
        "\n",
        "    print(f\"\\n{name} Statistics:\")\n",
        "    print(f\"  Average words per text:      {np.mean(lengths):.1f}\")\n",
        "    print(f\"  Average characters per text: {np.mean(char_lengths):.1f}\")\n",
        "    print(f\"  Median words:                {np.median(lengths):.1f}\")\n",
        "    print(f\"  Min words:                   {min(lengths)}\")\n",
        "    print(f\"  Max words:                   {max(lengths)}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"METHOD 1: BASIC TEXT STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "text_stats(selfma_texts, \"SelfMA\")\n",
        "text_stats(toxigen_texts, \"ToxiGen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkMuftgbKChX",
        "outputId": "e2138348-1def-46d8-eb04-d8c6bbd4b383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "METHOD 1: BASIC TEXT STATISTICS\n",
            "======================================================================\n",
            "\n",
            "SelfMA Statistics:\n",
            "  Average words per text:      15.5\n",
            "  Average characters per text: 82.4\n",
            "  Median words:                12.0\n",
            "  Min words:                   1\n",
            "  Max words:                   416\n",
            "\n",
            "ToxiGen Statistics:\n",
            "  Average words per text:      18.1\n",
            "  Average characters per text: 94.9\n",
            "  Median words:                18.0\n",
            "  Min words:                   1\n",
            "  Max words:                   102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocab(texts):\n",
        "    \"\"\"Get unique words from texts\"\"\"\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        words = text.lower().split()\n",
        "        all_words.extend(words)\n",
        "    return set(all_words)\n",
        "\n",
        "selfma_vocab = get_vocab(selfma_texts)\n",
        "toxigen_vocab = get_vocab(toxigen_texts)\n",
        "\n",
        "vocab_overlap = len(selfma_vocab & toxigen_vocab)  # Intersection\n",
        "vocab_union = len(selfma_vocab | toxigen_vocab)    # Union\n",
        "jaccard = vocab_overlap / vocab_union\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 2: VOCABULARY OVERLAP\")\n",
        "print(\"=\"*70)\n",
        "print(f\"SelfMA unique words:    {len(selfma_vocab):,}\")\n",
        "print(f\"ToxiGen unique words:   {len(toxigen_vocab):,}\")\n",
        "print(f\"Shared words:           {vocab_overlap:,}\")\n",
        "print(f\"Jaccard similarity:     {jaccard:.3f}\")\n",
        "print(f\"\\nüí° Jaccard > 0.5 = high overlap (similar vocabularies)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzadthELKO9f",
        "outputId": "1a150bbb-e8e2-4b89-9de6-ccc2812b51af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "METHOD 2: VOCABULARY OVERLAP\n",
            "======================================================================\n",
            "SelfMA unique words:    4,223\n",
            "ToxiGen unique words:   6,193\n",
            "Shared words:           1,673\n",
            "Jaccard similarity:     0.191\n",
            "\n",
            "üí° Jaccard > 0.5 = high overlap (similar vocabularies)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def top_words(texts, n=20):\n",
        "    \"\"\"Get most common words\"\"\"\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        words = text.lower().split()\n",
        "        # Remove common stop words manually\n",
        "        words = [w for w in words if w not in ['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'is', 'are', 'was', 'were', 'be', 'been']]\n",
        "        all_words.extend(words)\n",
        "\n",
        "    counter = Counter(all_words)\n",
        "    return counter.most_common(n)\n",
        "\n",
        "selfma_top = top_words(selfma_texts, 15)\n",
        "toxigen_top = top_words(toxigen_texts, 15)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 3: MOST COMMON WORDS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nSelfMA Top 15:\")\n",
        "for word, count in selfma_top:\n",
        "    print(f\"  {word:15s} {count:5d}\")\n",
        "\n",
        "print(\"\\nToxiGen Top 15:\")\n",
        "for word, count in toxigen_top:\n",
        "    print(f\"  {word:15s} {count:5d}\")\n",
        "\n",
        "# Check overlap in top words\n",
        "selfma_top_words = set([w for w, c in selfma_top])\n",
        "toxigen_top_words = set([w for w, c in toxigen_top])\n",
        "top_overlap = len(selfma_top_words & toxigen_top_words)\n",
        "\n",
        "print(f\"\\nTop words overlap: {top_overlap}/15\")\n",
        "print(f\"üí° More overlap = more similar language use\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qs9MZp4KWNV",
        "outputId": "60f7f2f2-b7fc-4f71-9fce-d861903f7101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "METHOD 3: MOST COMMON WORDS\n",
            "======================================================================\n",
            "\n",
            "SelfMA Top 15:\n",
            "  you               765\n",
            "  i                 514\n",
            "  that              231\n",
            "  like              216\n",
            "  you're            214\n",
            "  don't             213\n",
            "  so                205\n",
            "  your              199\n",
            "  have              185\n",
            "  just              183\n",
            "  not               151\n",
            "  it                147\n",
            "  it's              134\n",
            "  they              133\n",
            "  do                107\n",
            "\n",
            "ToxiGen Top 15:\n",
            "  i                 945\n",
            "  you               790\n",
            "  not               740\n",
            "  they              708\n",
            "  have              553\n",
            "  that              502\n",
            "  it                447\n",
            "  if                391\n",
            "  as                347\n",
            "  people            332\n",
            "  should            310\n",
            "  there             253\n",
            "  who               232\n",
            "  all               223\n",
            "  because           219\n",
            "\n",
            "Top words overlap: 7/15\n",
            "üí° More overlap = more similar language use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def punctuation_stats(texts, name):\n",
        "    \"\"\"Analyze punctuation usage\"\"\"\n",
        "    exclamation = sum(text.count('!') for text in texts) / len(texts)\n",
        "    question = sum(text.count('?') for text in texts) / len(texts)\n",
        "    period = sum(text.count('.') for text in texts) / len(texts)\n",
        "    comma = sum(text.count(',') for text in texts) / len(texts)\n",
        "\n",
        "    print(f\"\\n{name} Punctuation (avg per text):\")\n",
        "    print(f\"  ! (exclamation): {exclamation:.2f}\")\n",
        "    print(f\"  ? (question):    {question:.2f}\")\n",
        "    print(f\"  . (period):      {period:.2f}\")\n",
        "    print(f\"  , (comma):       {comma:.2f}\")\n",
        "\n",
        "    return exclamation, question, period, comma\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 4: PUNCTUATION PATTERNS\")\n",
        "print(\"=\"*70)\n",
        "selfma_punct = punctuation_stats(selfma_texts, \"SelfMA\")\n",
        "toxigen_punct = punctuation_stats(toxigen_texts, \"ToxiGen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxdiyCUDK7T9",
        "outputId": "ecb312f6-eb05-463c-85ef-714068dba54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "METHOD 4: PUNCTUATION PATTERNS\n",
            "======================================================================\n",
            "\n",
            "SelfMA Punctuation (avg per text):\n",
            "  ! (exclamation): 0.30\n",
            "  ? (question):    0.37\n",
            "  . (period):      1.24\n",
            "  , (comma):       0.71\n",
            "\n",
            "ToxiGen Punctuation (avg per text):\n",
            "  ! (exclamation): 0.02\n",
            "  ? (question):    0.04\n",
            "  . (period):      0.29\n",
            "  , (comma):       0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat\n",
        "import textstat"
      ],
      "metadata": {
        "id": "4iJtAHsdSBog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84db2a0e-4623-4879-e881-5740f94ba46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.11-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (4.67.1)\n",
            "Downloading textstat-0.7.11-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.17.2 textstat-0.7.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_readability(texts, name):\n",
        "    \"\"\"Calculate multiple readability metrics\"\"\"\n",
        "\n",
        "    # Calculate for each text\n",
        "    flesch_reading_ease = [textstat.flesch_reading_ease(text) for text in texts]\n",
        "    flesch_kincaid_grade = [textstat.flesch_kincaid_grade(text) for text in texts]\n",
        "    dale_chall_readability_score = [textstat.dale_chall_readability_score(text) for text in texts]\n",
        "    gunning_fog = [textstat.gunning_fog(text) for text in texts]\n",
        "    smog_index = [textstat.smog_index(text) for text in texts]\n",
        "    automated_readability = [textstat.automated_readability_index(text) for text in texts]\n",
        "    coleman_liau = [textstat.coleman_liau_index(text) for text in texts]\n",
        "\n",
        "    print(f\"\\n{name} Readability Scores:\")\n",
        "    print(f\"  Flesch Reading Ease:             {np.mean(flesch_reading_ease):.1f} (higher = easier)\")\n",
        "    print(f\"  Flesch-Kincaid Grade:            {np.mean(flesch_kincaid_grade):.1f} (grade level)\")\n",
        "    print(f\"  Dale-Chall Readability Score:    {np.mean(dale_chall_readability_score):.1f} (readability score)\")\n",
        "    print(f\"  Gunning Fog Index:               {np.mean(gunning_fog):.1f} (grade level)\")\n",
        "    print(f\"  SMOG Index:                      {np.mean(smog_index):.1f} (grade level)\")\n",
        "    print(f\"  Automated Readability:           {np.mean(automated_readability):.1f} (grade level)\")\n",
        "    print(f\"  Coleman-Liau Index:              {np.mean(coleman_liau):.1f} (grade level)\")\n",
        "\n",
        "    return {\n",
        "        'flesch_reading_ease': np.mean(flesch_reading_ease),\n",
        "        'flesch_kincaid_grade': np.mean(flesch_kincaid_grade),\n",
        "        'dale_chall_readability_score': np.mean(dale_chall_readability_score),\n",
        "        'gunning_fog': np.mean(gunning_fog),\n",
        "        'smog': np.mean(smog_index),\n",
        "        'ari': np.mean(automated_readability),\n",
        "        'coleman_liau': np.mean(coleman_liau)\n",
        "    }\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"READABILITY ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "selfma_readability = calculate_readability(selfma_texts, \"SelfMA\")\n",
        "toxigen_readability = calculate_readability(toxigen_texts, \"ToxiGen\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7_b6AZ0NCfB",
        "outputId": "333b3b1e-73fc-4afe-85f1-ace15bcd1921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "READABILITY ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "SelfMA Readability Scores:\n",
            "  Flesch Reading Ease:             85.4 (higher = easier)\n",
            "  Flesch-Kincaid Grade:            3.8 (grade level)\n",
            "  Dale-Chall Readability Score:    6.5 (readability score)\n",
            "  Gunning Fog Index:               6.1 (grade level)\n",
            "  SMOG Index:                      6.3 (grade level)\n",
            "  Automated Readability:           4.3 (grade level)\n",
            "  Coleman-Liau Index:              4.1 (grade level)\n",
            "\n",
            "ToxiGen Readability Scores:\n",
            "  Flesch Reading Ease:             67.1 (higher = easier)\n",
            "  Flesch-Kincaid Grade:            8.0 (grade level)\n",
            "  Dale-Chall Readability Score:    7.7 (readability score)\n",
            "  Gunning Fog Index:               10.2 (grade level)\n",
            "  SMOG Index:                      9.1 (grade level)\n",
            "  Automated Readability:           7.7 (grade level)\n",
            "  Coleman-Liau Index:              6.9 (grade level)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SBIC SelfMA Readability ###"
      ],
      "metadata": {
        "id": "anbOfSMTBpGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"READABILITY ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "balanced_selfMA_ds = load_from_disk(\"/content/drive/MyDrive/266_project/balanced_selfMA_ds\")\n",
        "balanced_selfMA_ds = balanced_selfMA_ds.rename_column('text', 'cleaned_text')\n",
        "\n",
        "all_data = pd.concat([\n",
        "    balanced_selfMA_ds['train'].to_pandas(),\n",
        "    balanced_selfMA_ds['validation'].to_pandas(),\n",
        "    balanced_selfMA_ds['test'].to_pandas()\n",
        "])\n",
        "\n",
        "selfma_texts = all_data[all_data['label'] == 1]['cleaned_text'].tolist()  # All microaggressions = SelfMA\n",
        "sbic_texts = all_data[all_data['label'] == 0]['cleaned_text'].tolist()  # Benign = SBIC\n",
        "\n",
        "\n",
        "selfma_readability = calculate_readability(selfma_texts, \"SelfMA\")\n",
        "sbic_readability = calculate_readability(sbic_texts, \"SBIC\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5Cfc4gGBr97",
        "outputId": "2b1a2bc8-fc43-4398-d154-36463fb3ac8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "READABILITY ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "SelfMA Readability Scores:\n",
            "  Flesch Reading Ease:             70.9 (higher = easier)\n",
            "  Flesch-Kincaid Grade:            7.0 (grade level)\n",
            "  Dale-Chall Readability Score:    8.1 (readability score)\n",
            "  Gunning Fog Index:               9.2 (grade level)\n",
            "  SMOG Index:                      9.5 (grade level)\n",
            "  Automated Readability:           7.5 (grade level)\n",
            "  Coleman-Liau Index:              7.0 (grade level)\n",
            "\n",
            "SBIC Readability Scores:\n",
            "  Flesch Reading Ease:             69.4 (higher = easier)\n",
            "  Flesch-Kincaid Grade:            7.4 (grade level)\n",
            "  Dale-Chall Readability Score:    9.5 (readability score)\n",
            "  Gunning Fog Index:               9.5 (grade level)\n",
            "  SMOG Index:                      8.7 (grade level)\n",
            "  Automated Readability:           8.7 (grade level)\n",
            "  Coleman-Liau Index:              8.1 (grade level)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Workplace MA Readability ###"
      ],
      "metadata": {
        "id": "s5ExEe-IChWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "micro_agg_url = \"https://huggingface.co/spaces/khanak27/microaggressionsdetector/resolve/main/micro_agg.csv\"\n",
        "# Try different encodings to handle Unicode issues\n",
        "encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1', 'utf-8-sig']\n",
        "\n",
        "df_micro = None\n",
        "for encoding in encodings_to_try:\n",
        "    try:\n",
        "        print(f\"Trying encoding: {encoding}\")\n",
        "        df_micro = pd.read_csv(micro_agg_url, encoding=encoding)\n",
        "        print(f\"‚úÖ Successfully loaded with {encoding} encoding\")\n",
        "        break\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"‚ùå Failed with {encoding}: {str(e)[:100]}...\")\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Other error with {encoding}: {str(e)[:100]}...\")\n",
        "        continue\n",
        "\n",
        "if df_micro is None:\n",
        "    print(\"‚ùå Failed to load dataset with any encoding. Trying with error handling...\")\n",
        "    try:\n",
        "        df_micro = pd.read_csv(micro_agg_url, encoding='utf-8', encoding_errors='replace')\n",
        "        print(\"‚úÖ Loaded with UTF-8 and error replacement\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Final attempt failed: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwPOmkY8CkRE",
        "outputId": "5e7ad7f0-9524-42f1-d410-e7cc37857ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying encoding: utf-8\n",
            "‚ùå Failed with utf-8: 'utf-8' codec can't decode byte 0xe2 in position 17: invalid continuation byte...\n",
            "Trying encoding: latin-1\n",
            "‚úÖ Successfully loaded with latin-1 encoding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_micro_positive_labels = df_micro[df_micro['label'] == 1]['speech'].tolist()  # All microaggressions = WorkplaceMA\n",
        "df_micro_negative_labels = df_micro[df_micro['label'] == 0]['speech'].tolist()  # Benign = WorkplaceMA\n",
        "\n",
        "\n",
        "df_micro_positive_labels_readability = calculate_readability(df_micro_positive_labels, \"Workplace MA - microaggressions\")\n",
        "df_micro_negative_labels_readability = calculate_readability(df_micro_negative_labels, \"Workplace MA - nonmicroaggressions\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyAl7FM0EIlu",
        "outputId": "1cc4811b-7845-4ec3-a842-e4b191a22f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Workplace MA - microaggressions Readability Scores:\n",
            "  Flesch Reading Ease:             80.3 (higher = easier)\n",
            "  Flesch-Kincaid Grade:            3.7 (grade level)\n",
            "  Dale-Chall Readability Score:    6.0 (readability score)\n",
            "  Gunning Fog Index:               6.6 (grade level)\n",
            "  SMOG Index:                      6.6 (grade level)\n",
            "  Automated Readability:           4.7 (grade level)\n",
            "  Coleman-Liau Index:              5.5 (grade level)\n",
            "\n",
            "Workplace MA - nonmicroaggressions Readability Scores:\n",
            "  Flesch Reading Ease:             74.6 (higher = easier)\n",
            "  Flesch-Kincaid Grade:            4.6 (grade level)\n",
            "  Dale-Chall Readability Score:    8.6 (readability score)\n",
            "  Gunning Fog Index:               6.5 (grade level)\n",
            "  SMOG Index:                      6.6 (grade level)\n",
            "  Automated Readability:           5.5 (grade level)\n",
            "  Coleman-Liau Index:              7.5 (grade level)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XmKCdVSFJua"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}