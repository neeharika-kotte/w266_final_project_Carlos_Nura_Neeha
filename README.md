Proposal:[1][2]
The term “microaggression” was coined by African American psychiatrist and Harvard professor Chester Pierce in 1978 to describe “subtle” and “often automatic” offenses directed against people of color. Since then, the concept has been extended to other marginalized groups. [3]When racial, they are, according to one prominent group of scholars,  “brief and commonplace daily verbal, behavioral, or environmental indignities, whether intentional or unintentional, that communicate hostile, derogatory, or negative racial slights and insults towards people of color” (D.W. Sue, Capodilupo, et. al., 2007). [4]Because microaggressions often perpetuate subtle forms of bias, they can often be difficult to identify accurately, particularly in text.

Therefore, our aim is to use natural language processing techniques to help us identify these phenomena when they are articulated in text. Our approach involves fine-tuning a DeBERTa-v3 or RoBERTa encoder into a classifier trained on two families of signals: 1) sarcasm, and 2) racist content; including, more specifically, implicit hatred, social bias, and toxicity directed toward racial identity. Our goal is to build a classifier which can detect sarcastic, racially biased remarks, i.e. one form of racial microaggression.

We will use public datasets, referenced by existing literature, to train on these signals: ToxiGen for implicit hate (referenced by Hartvigsen et al., 2022), Social Bias Inference Corpus (SBIC) for[5] social bias, Jigsaw for identity-aware toxicity (referenced by Sahoo et al., 2022), and Self-Annotated Reddit Corpus (SARC) and/or iSarcasmEval (referenced by Abu Farha et al., 2022) for sarcasm.

While labeled microaggressions datasets are challenging to find, prior work on detecting microaggressions with NLP, such as Breitfeller et al., EMNLP-IJCNLP 2019, commonly references a compiled source of microaggressive comments from Tumblr: www.microaggressions.com. [6]We plan to scrape racially microaggressive comments from this website (tagged with “race”)  and then test the extent to which our algorithm is able to positively label these statements as microaggressions. 